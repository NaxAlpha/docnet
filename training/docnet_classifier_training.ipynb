{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "docnet-classifier-training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP5pfeJRAMWZ5ZNWNMFOV5m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "048caf9c6c69482a9a2b3c18069ec004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3e4aa8d9458c4c1d938fa1edfa73a2fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_120b043fba8c4453abc4417c11c5a650",
              "IPY_MODEL_9db228fc974545d1a4b9fc7f338e67c9"
            ]
          }
        },
        "3e4aa8d9458c4c1d938fa1edfa73a2fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "120b043fba8c4453abc4417c11c5a650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4e4a2b58d9a944f09a123a71f708b0c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 3482,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3482,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa240b0ee9af4beaa2b2438834fdf62c"
          }
        },
        "9db228fc974545d1a4b9fc7f338e67c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e1802e50a9834c0bbd187d26c58bd58f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 3482/3482 [04:10&lt;00:00, 15.04it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_659fd3ccfbe24322b5a24e3555a20e01"
          }
        },
        "4e4a2b58d9a944f09a123a71f708b0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa240b0ee9af4beaa2b2438834fdf62c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1802e50a9834c0bbd187d26c58bd58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "659fd3ccfbe24322b5a24e3555a20e01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4216f9f5d9e840c9ad3dcab3a168c5f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_85e2ecd7b1b0414290a7cd24ff85d529",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d9647eed2399499ab96d63dbdd7a9994",
              "IPY_MODEL_2fe43cb3446b44689824c255feee16d6"
            ]
          }
        },
        "85e2ecd7b1b0414290a7cd24ff85d529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9647eed2399499ab96d63dbdd7a9994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_252c86e5bd3b42d6a06e65f8b561175e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 33,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 33,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bdda8089e7044239a30bad4254474fd"
          }
        },
        "2fe43cb3446b44689824c255feee16d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1085661996244b829da558936ad0a285",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 33/33 [00:12&lt;00:00,  6.71it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff2c4ead08a84f6f9a1d5e2440a33284"
          }
        },
        "252c86e5bd3b42d6a06e65f8b561175e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bdda8089e7044239a30bad4254474fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1085661996244b829da558936ad0a285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff2c4ead08a84f6f9a1d5e2440a33284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaxAlpha/docnet/blob/master/training/docnet_classifier_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b20DkSpKhjD",
        "colab_type": "code",
        "outputId": "18cfef25-9060-42b9-9430-bf9e80592abf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "# @title Setup variables and configuration\n",
        "import os\n",
        "from google.colab import auth\n",
        "\n",
        "ROOT_DIR='' #@param {type:\"string\"}\n",
        "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
        "TEMP_DIR = '/tmp/docnet'\n",
        "\n",
        "if 'gs://' in ROOT_DIR:\n",
        "    auth.authenticate_user()\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.18)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.18)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwKW7cUSi0cJ",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 1 - Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfmjkKx2TucY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title Load dataset\n",
        "# https://github.com/Quicksign/ocrized-text-dataset/blob/master/tobacco3482.sh\n",
        "!echo \"Setting up Tesseract...\"\n",
        "!mkdir -p '$TEMP_DIR'\n",
        "!apt install -y tesseract-ocr\n",
        "!pip install pytesseract\n",
        "\n",
        "!echo \"Downloading files from UMIACS server...\"\n",
        "!wget -O $TEMP_DIR/1.zip -nv --show-progress -c http://lampsrv02.umiacs.umd.edu/projdb/edit/userfiles/datasets/Tobacco3482_1.zip\n",
        "!wget -O $TEMP_DIR/2.zip -nv --show-progress -c http://lampsrv02.umiacs.umd.edu/projdb/edit/userfiles/datasets/Tobacco3482_2.zip\n",
        "\n",
        "!echo \"Decompressing .zip archives...\"\n",
        "!unzip -d '$TEMP_DIR' -q -n '$TEMP_DIR'/*.zip\n",
        "\n",
        "!echo \"Moving content to data directory...\"\n",
        "!rm '$TEMP_DIR'/*.zip\n",
        "!gsutil -m cp -r '$TEMP_DIR' '$DATA_DIR'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFu7tVnrLTaf",
        "colab_type": "code",
        "outputId": "a8f9a921-6eae-4cd4-a7cd-15f3f9649202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "048caf9c6c69482a9a2b3c18069ec004",
            "3e4aa8d9458c4c1d938fa1edfa73a2fd",
            "120b043fba8c4453abc4417c11c5a650",
            "9db228fc974545d1a4b9fc7f338e67c9",
            "4e4a2b58d9a944f09a123a71f708b0c1",
            "fa240b0ee9af4beaa2b2438834fdf62c",
            "e1802e50a9834c0bbd187d26c58bd58f",
            "659fd3ccfbe24322b5a24e3555a20e01"
          ]
        }
      },
      "source": [
        "# @title Perform OCR on document images\n",
        "# https://github.com/Quicksign/ocrized-text-dataset/blob/master/to_text.py\n",
        "import argparse\n",
        "import os\n",
        "import pytesseract\n",
        "\n",
        "import tensorflow as tf\n",
        "from builtins import str\n",
        "from joblib import Parallel, delayed\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from threading import Thread\n",
        "\n",
        "\n",
        "def to_text(filename, lang=\"eng\", format_=\"txt\", ignore_error=False):\n",
        "    try:\n",
        "        base, fn = os.path.split(filename)\n",
        "        temp_filename = os.path.join(TEMP_DIR, fn)\n",
        "        \n",
        "        basename, ext = os.path.splitext(temp_filename)\n",
        "        target = basename + \".\" + format_\n",
        "        _, fn = os.path.split(target)\n",
        "        new_filename = os.path.join(base, fn)\n",
        "        # implement caching mechanism\n",
        "        # Check if file exists - skip it\n",
        "        if tf.io.gfile.exists(new_filename):\n",
        "            return\n",
        "\n",
        "        tf.io.gfile.copy(filename, temp_filename, True)\n",
        "        im = Image.open(temp_filename)\n",
        "        if format_ == \"txt\":\n",
        "            tess_output = pytesseract.image_to_string(im, lang=lang, config=\"--psm 3 --oem 1\")\n",
        "        elif format_ == \"hocr\":\n",
        "            tess_output = pytesseract.image_to_pdf_or_hocr(\n",
        "                im, lang=lang, config=\"--psm 3 --oem 1\", extension=format_\n",
        "            )\n",
        "        with open(target, \"w\") as fp:\n",
        "            fp.write(str(tess_output))\n",
        "        tf.io.gfile.copy(target, new_filename, True)\n",
        "    except Exception as e:\n",
        "        if ignore_error:\n",
        "            print(\"Error: {}\".format(e))\n",
        "        else:\n",
        "            raise e\n",
        "\n",
        "def worker(files):\n",
        "    for f in files:\n",
        "        to_text(f)\n",
        "        prog.update(1)\n",
        "\n",
        "filenames = tf.io.gfile.glob(os.path.join(DATA_DIR, '**', '*.tif'))\n",
        "# Only run on first 100 files\n",
        "# because it can take very long to run on colab\n",
        "# ideally would run on 16 core machine\n",
        "filenames = filenames[:100]  \n",
        "prog = tqdm(filenames)\n",
        "\n",
        "th = []\n",
        "n = 4\n",
        "m = len(filenames)//n\n",
        "for i in range(n+1):\n",
        "    chunk = filenames[i*m:(i+1)*m]\n",
        "    t = Thread(target=worker, args=(chunk, ))\n",
        "    t.start()\n",
        "    th.append(t)\n",
        "for t in th:\n",
        "    t.join()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "048caf9c6c69482a9a2b3c18069ec004",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=3482), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZIUOrkUi8bZ",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 2 - Data analysis and Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhLcGe8ZPo3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data\n",
        "!gsutil -m cp -r $DATA_DIR/* data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I02Q0tsTOIqu",
        "colab_type": "code",
        "outputId": "e1ef867c-2645-4630-cef9-8bb2b16da680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "# @title Get file names and labels\n",
        "import tensorflow as tf\n",
        "\n",
        "image_files = tf.io.gfile.glob(os.path.join('data/**', '*.tif'))\n",
        "text_files = [os.path.splitext(fn)[0] + '.txt' for fn in image_files]\n",
        "labels = [fn.split('/')[-2] for fn in image_files]\n",
        "classes = list(set(labels))\n",
        "labels = [classes.index(lbl) for lbl in labels]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bTMEk_2lKnA",
        "colab_type": "code",
        "outputId": "4879fcc8-f8b2-401f-d401-d875a126b59a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "# @title Visualize class distribution\n",
        "from collections import Counter\n",
        "\n",
        "class_dist = Counter(labels)\n",
        "\n",
        "print('Number of Files:', len(image_files))\n",
        "print('Number of Classes:', len(classes))\n",
        "\n",
        "print()\n",
        "print('Class distribution:')\n",
        "print()\n",
        "\n",
        "def print_class_dist(image_files):\n",
        "    labels = [fn.split('/')[-2] for fn in image_files]\n",
        "    class_dist = Counter(labels)\n",
        "    print('{:>12}  {:>12}  {:>13}'.format('-'*12, '-'*12, '-'*12))\n",
        "    print('{:>12}  {:>12}  {:>13}'.format('Class', 'Count', 'Percentage'))\n",
        "    print('{:>12}  {:>12}  {:>13}'.format('-'*12, '-'*12, '-'*12))\n",
        "    for lbl, cnt in class_dist.items():\n",
        "        perc = round(100*cnt/len(labels), 2)\n",
        "        print('{:>12}  {:>12}  {:>12}%'.format(lbl, cnt, perc))\n",
        "\n",
        "print_class_dist(image_files)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Files: 3482\n",
            "Number of Classes: 10\n",
            "\n",
            "Class distribution:\n",
            "\n",
            "------------  ------------   ------------\n",
            "       Class         Count     Percentage\n",
            "------------  ------------   ------------\n",
            "       Email           599          17.2%\n",
            "  Scientific           261           7.5%\n",
            "      Resume           120          3.45%\n",
            "        Note           201          5.77%\n",
            "        ADVE           230          6.61%\n",
            "        Memo           620         17.81%\n",
            "        Form           431         12.38%\n",
            "      Report           265          7.61%\n",
            "      Letter           567         16.28%\n",
            "        News           188           5.4%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpgiYmLaF7tV",
        "colab_type": "code",
        "outputId": "6c3a730c-54bb-4144-bc34-1f35fc6c9708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "# @title Split Data into train/validation\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(10)\n",
        "np.random.shuffle(image_files)\n",
        "\n",
        "N = int(len(image_files)*0.85)  # 15% for validation\n",
        "train, valid = image_files[:N], image_files[N:]\n",
        "\n",
        "print('Train Distribution:')\n",
        "print_class_dist(train)\n",
        "\n",
        "print()\n",
        "print('Validation Distribution:')\n",
        "print_class_dist(valid)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Distribution:\n",
            "------------  ------------   ------------\n",
            "       Class         Count     Percentage\n",
            "------------  ------------   ------------\n",
            "        Note           176          5.95%\n",
            "        Memo           533         18.01%\n",
            "        ADVE           188          6.35%\n",
            "       Email           500          16.9%\n",
            "        News           164          5.54%\n",
            "      Letter           483         16.32%\n",
            "        Form           360         12.17%\n",
            "      Report           224          7.57%\n",
            "  Scientific           230          7.77%\n",
            "      Resume           101          3.41%\n",
            "\n",
            "Validation Distribution:\n",
            "------------  ------------   ------------\n",
            "       Class         Count     Percentage\n",
            "------------  ------------   ------------\n",
            "        Memo            87         16.63%\n",
            "      Letter            84         16.06%\n",
            "      Report            41          7.84%\n",
            "        Form            71         13.58%\n",
            "       Email            99         18.93%\n",
            "        News            24          4.59%\n",
            "  Scientific            31          5.93%\n",
            "        Note            25          4.78%\n",
            "      Resume            19          3.63%\n",
            "        ADVE            42          8.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ_aJpYqpc77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title Create Dataset loading classes\n",
        "import torch\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from threading import Thread\n",
        "\n",
        "\n",
        "class DocDataset(Dataset):\n",
        "\n",
        "    def __init__(self, images, tokenizer, image_size=(299, 299), text_max_len=256, transform=None):\n",
        "        self.images = images\n",
        "        self.tokenizer = tokenizer\n",
        "        self.transform = transform\n",
        "        self.image_size = image_size\n",
        "        self.text_max_len = text_max_len\n",
        "        self.cache = dict()\n",
        "        self._setup()\n",
        "\n",
        "    def _setup(self):\n",
        "        self.texts = [os.path.splitext(fn)[0] + '.txt' for fn in image_files]\n",
        "        labels = [fn.split('/')[-2] for fn in image_files]\n",
        "        self.classes = list(set(labels))\n",
        "        self.labels = [self.classes.index(lbl) for lbl in labels]\n",
        "        self.cache.update(\n",
        "            img=dict(),\n",
        "            txt=dict(),\n",
        "        )\n",
        "        # self._prog = tqdm(range(len(self)))\n",
        "        # self._start_caching(16)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def _start_caching(self, N):\n",
        "        th = []\n",
        "        for i in range(N):\n",
        "            t = Thread(target=self._cache_worker, args=(i, N))\n",
        "            t.start()\n",
        "            th.append(t)\n",
        "        for t in th:\n",
        "            t.join()\n",
        "    \n",
        "    def _cache_worker(self, idx, N):\n",
        "        for _ in range(idx, len(self), N):\n",
        "            _ = self[_]\n",
        "            self._prog.update(1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img = self.images[idx]\n",
        "        txt = self.texts[idx]\n",
        "        lbl = self.labels[idx]\n",
        "\n",
        "        if idx not in self.cache['img']:\n",
        "            with tf.io.gfile.GFile(img, 'rb') as f:\n",
        "                img = Image.open(f)\n",
        "                img = T.Resize(self.image_size)(img)\n",
        "            self.cache['img'][idx] = img\n",
        "\n",
        "        img = self.cache['img'][idx]\n",
        "        img = T.Grayscale(3)(img)\n",
        "        img = T.ToTensor()(img)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if idx not in self.cache['txt']:\n",
        "            with tf.io.gfile.GFile(txt) as f:\n",
        "                txt = f.read()\n",
        "                \n",
        "            txt = self.tokenizer.encode(txt, max_length=self.text_max_len)\n",
        "            txt = txt[:self.text_max_len]\n",
        "            txt = txt + [0] * (self.text_max_len - len(txt))\n",
        "            self.cache['txt'][idx] = txt\n",
        "\n",
        "        txt = self.cache['txt'][idx]\n",
        "        txt = torch.tensor(txt)\n",
        "        lbl = torch.tensor(lbl)\n",
        "\n",
        "        return img, txt, lbl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FYZ8qtIuuR4",
        "colab_type": "code",
        "outputId": "8fe456e3-3ac8-44f3-c677-d27966ac8860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# @title Test dataset and caching\n",
        "from transformers import *\n",
        "transform = T.Compose([\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "tok = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "data_test = DocDataset(train, tok, transform=transform)\n",
        "\n",
        "i, t, l = data_test[0]\n",
        "print(i.shape, t.shape, l)\n",
        "print(len(data_test[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 299, 299]) torch.Size([256]) tensor(4)\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3msFS5MoVDz",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# Modelling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZgKSvl06Fagh",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "from transformers import *\n",
        "from torchvision.models import *\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(classes)).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL9CYqdsIOR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_data = DocDataset(train, tokenizer, (224, 224), 256, transform)\n",
        "valid_data = DocDataset(valid, tokenizer, (224, 224), 256, transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=4, shuffle=True, num_workers=8)\n",
        "valid_loader = DataLoader(valid_data, batch_size=16, shuffle=False, num_workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFhM3-_r6lpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGXuxZ5NJc34",
        "colab_type": "code",
        "outputId": "af2fefcf-1219-4144-ee0a-508449163800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351,
          "referenced_widgets": [
            "4216f9f5d9e840c9ad3dcab3a168c5f2",
            "85e2ecd7b1b0414290a7cd24ff85d529",
            "d9647eed2399499ab96d63dbdd7a9994",
            "2fe43cb3446b44689824c255feee16d6",
            "252c86e5bd3b42d6a06e65f8b561175e",
            "5bdda8089e7044239a30bad4254474fd",
            "1085661996244b829da558936ad0a285",
            "ff2c4ead08a84f6f9a1d5e2440a33284"
          ]
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "\n",
        "def calc_report():\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    lblsx = []\n",
        "\n",
        "    for i, data in enumerate(tqdm(valid_loader), 0):\n",
        "        imgs, txts, lbls = data\n",
        "        imgs, txts, lbls = map(lambda d: d.to(device), [imgs, txts, lbls])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(txts)[0]\n",
        "            pred = pred.argmax(-1)\n",
        "        \n",
        "        lblsx += lbls.tolist()\n",
        "        preds += pred.tolist()\n",
        "        \n",
        "    print(classification_report(lblsx, preds))\n",
        "    model.train()\n",
        "\n",
        "calc_report()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4216f9f5d9e840c9ad3dcab3a168c5f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=33), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        88\n",
            "           1       0.95      1.00      0.97        53\n",
            "           2       1.00      0.76      0.86        45\n",
            "           3       0.93      0.95      0.94        40\n",
            "           4       0.91      1.00      0.95        31\n",
            "           5       0.98      0.98      0.98        45\n",
            "           6       0.98      1.00      0.99        86\n",
            "           7       1.00      1.00      1.00        19\n",
            "           8       0.99      0.99      0.99        77\n",
            "           9       0.90      0.95      0.92        39\n",
            "\n",
            "    accuracy                           0.97       523\n",
            "   macro avg       0.96      0.96      0.96       523\n",
            "weighted avg       0.97      0.97      0.97       523\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azGDFFQEIEYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(5): \n",
        "\n",
        "    valid_iter = iter(valid_loader)\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        model.train()\n",
        "        \n",
        "        imgs, txts, lbls = data\n",
        "        imgs, txts, lbls = map(lambda d: d.to(device), [imgs, txts, lbls])\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(txts)[0]\n",
        "        loss = criterion(outputs, lbls)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 20 == 19:\n",
        "            model.eval()\n",
        "\n",
        "            imgs, txts, lbls = map(lambda d: d.to(device), next(valid_iter))\n",
        "            with torch.no_grad():\n",
        "                outputs = model(txts)[0]\n",
        "                val_loss = criterion(outputs, lbls)\n",
        "\n",
        "            model.train()\n",
        "            print('[%d, %5d]  Train Loss: %.3f  Valid Loss: %.3f' % (epoch + 1, i + 1, running_loss / 20, val_loss))\n",
        "            running_loss = 0\n",
        "\n",
        "        if i % 500 == 499:\n",
        "            valid_iter = iter(valid_loader)\n",
        "\n",
        "    calc_report()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z2R7fG_G33V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "df8c3e4a-86d5-4c45-e8ba-70608aa986d1"
      },
      "source": [
        "model.config.id2label = dict(enumerate(classes))\n",
        "!mkdir -p doc-class\n",
        "model.save_pretrained('doc-class')\n",
        "!zip -r model.zip doc-class\n",
        "!gsutil -m cp model.zip $ROOT_DIR/"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: doc-class/ (stored 0%)\n",
            "updating: doc-class/config.json (deflated 55%)\n",
            "updating: doc-class/pytorch_model.bin (deflated 7%)\n",
            "Copying file://model.zip [Content-Type=application/zip]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "\\ [1/1 files][386.5 MiB/386.5 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/386.5 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}